{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c22f02",
   "metadata": {},
   "source": [
    "# Making Transformers Efficient in Production\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d157c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing \n",
    "import numpy as np\n",
    "\n",
    "# Data Management\n",
    "import pandas as pd\n",
    "\n",
    "# Transformers\n",
    "from transformers import Trainer\n",
    "from transformers import pipeline\n",
    "from transformers import AutoConfig\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "from transformers.convert_graph_to_onnx import convert\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# SciPy\n",
    "from scipy.special import softmax\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import quantize_per_tensor\n",
    "from torch.nn.quantized import QFunctional\n",
    "from torch.quantization import quantize_dynamic\n",
    "\n",
    "# Path Set-up\n",
    "from pathlib import Path\n",
    "\n",
    "# Datasets\n",
    "from datasets import load_metric \n",
    "from datasets import load_dataset\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Time & OS\n",
    "import os\n",
    "import sys\n",
    "from time import perf_counter\n",
    "\n",
    "# from psutil import cpu_count\n",
    "\n",
    "# Hyperparamter Tuning\n",
    "import optuna \n",
    "\n",
    "# Toolkits\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes,mark_inset\n",
    "from onnxruntime import (GraphOptimizationLevel, InferenceSession, \n",
    "                         SessionOptions)\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53811831",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca41e2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'notebooks'...\n",
      "remote: Enumerating objects: 526, done.\u001b[K\n",
      "remote: Counting objects: 100% (526/526), done.\u001b[K\n",
      "remote: Compressing objects: 100% (289/289), done.\u001b[K\n",
      "remote: Total 526 (delta 251), reused 481 (delta 231), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (526/526), 29.30 MiB | 17.09 MiB/s, done.\n",
      "Resolving deltas: 100% (251/251), done.\n",
      "/Users/isisromero/Desktop/NLP_transformer/chap_08/notebooks\n",
      "‚è≥ Installing base requirements ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isisromero/anaconda3/envs/NLP_transformer/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Base requirements installed!\n",
      "‚è≥ Installing Git LFS ...\n",
      "‚úÖ Git LFS installed!\n"
     ]
    }
   ],
   "source": [
    "# Uncomment and run this cell if you're on Colab or Kaggle\n",
    "!git clone https://github.com/nlp-with-transformers/notebooks.git\n",
    "%cd notebooks\n",
    "\n",
    "from install import *\n",
    "install_requirements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b993233c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected! This notebook can be *very* slow without a GPU üê¢\n",
      "Using transformers v4.39.3\n",
      "Using datasets v2.19.0\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "setup_chapter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807c6eb9",
   "metadata": {},
   "source": [
    "### Intent Detection as a Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a69c7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f88f61726444b32a5521aa183307e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/8.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec609a48a3b6494d9070149c17376e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e83b1f550f4639b65f03af94cc016c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a7a0ab4f6e43a59c2421e94b625ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55713a90032a4cd8b139ff87f38c26a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=bert_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30fab2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'car_rental', 'score': 0.5490033626556396}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"Hey, I'd like to rent a vehicle from Nov 1st to Nov 15th in \n",
    "Paris and I need a 15 passenger van\"\"\"\n",
    "\n",
    "pipe(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90b64be",
   "metadata": {},
   "source": [
    "### Creating a Performance Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23550f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceBenchmark:\n",
    "    def __init__(self, pipeline, dataset, optim_type=\"BERT baseline\"):\n",
    "        self.pipeline = pipeline\n",
    "        self.dataset = dataset\n",
    "        self.optim_type = optim_type\n",
    "        \n",
    "    def compute_accuracy(self):\n",
    "        # We'll define this later\n",
    "        pass    \n",
    "\n",
    "    def compute_size(self):\n",
    "        # We'll define this later\n",
    "        pass\n",
    "\n",
    "    def time_pipeline(self):\n",
    "        # We'll define this later\n",
    "        pass\n",
    "    \n",
    "    def run_benchmark(self):\n",
    "        metrics = {}\n",
    "        metrics[self.optim_type] = self.compute_size()\n",
    "        metrics[self.optim_type].update(self.time_pipeline())\n",
    "        metrics[self.optim_type].update(self.compute_accuracy())\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "986f8e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed695250fab4a02a0eef7f5827efa53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/24.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1cba483dae4ae784196a1cb5607600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/312k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb9dbae90554c748b0ca0051f59e5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/77.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1b0e2956404dd28379e0e1d4a3d8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/136k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9faa8e3bb67f4d5a9b48ad9be86c5076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/15250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c169f2412eb04bb2a570ee5a885146e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74917d0f1dcf43f686414a9b1e0ed228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrieving & loading 'clinc' data\n",
    "clinc = load_dataset(\"clinc_oos\", \"plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48d632f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'transfer $100 from my checking to saving account', 'intent': 133}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = clinc[\"test\"][42]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23285aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transfer'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents = clinc[\"test\"].features[\"intent\"]\n",
    "intents.int2str(sample[\"intent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3b6c8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dk/f9pbhbp52qxc0613mpbtx8lm0000gn/T/ipykernel_53132/1364396659.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  accuracy_score = load_metric(\"accuracy\")\n",
      "/Users/isisromero/anaconda3/envs/NLP_transformer/lib/python3.11/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599b6a8402c74002863f8be2b8d4e3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute accuracy method() as follow:\n",
    "accuracy_score = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d85061d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(self):\n",
    "    \"\"\"This overrides the PerformanceBenchmark.compute_accuracy() method\"\"\"\n",
    "    preds, labels = [], []\n",
    "    for example in self.dataset:\n",
    "        pred = self.pipeline(example[\"text\"])[0][\"label\"]\n",
    "        label = example[\"intent\"]\n",
    "        preds.append(intents.str2int(pred))\n",
    "        labels.append(label)\n",
    "    accuracy = accuracy_score.compute(predictions=preds, references=labels)\n",
    "    print(f\"Accuracy on test set - {accuracy['accuracy']:.3f}\")\n",
    "    return accuracy\n",
    "\n",
    "PerformanceBenchmark.compute_accuracy = compute_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26012e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert.encoder.layer.2.attention.self.value.bias',\n",
       " tensor([-2.7834e-02,  4.9434e-02,  8.3551e-02,  4.1092e-02,  6.0157e-01,\n",
       "          1.1774e-01, -5.2112e-02, -6.5143e-02, -2.9358e-02, -4.2250e-02,\n",
       "          7.9177e-02,  8.0409e-02,  2.9921e-03,  1.7816e-01, -5.0480e-02,\n",
       "         -1.5634e-01, -2.1707e-02,  1.4381e-02,  2.5132e-02, -2.4110e-02,\n",
       "         -1.9183e-01, -7.8657e-02,  5.0709e-02,  3.3632e-02, -3.1946e-02,\n",
       "          1.1616e-01,  9.2720e-02, -1.1787e-01,  2.3233e-01, -1.2678e-02,\n",
       "         -1.3138e-01, -4.0024e-02,  7.4823e-02, -5.4148e-02, -1.5184e-01,\n",
       "         -7.4407e-02,  1.1559e-01,  8.2729e-02, -1.3787e-01,  8.3528e-02,\n",
       "          1.2154e-01,  1.6880e-02, -5.6629e-02, -3.9295e-02,  5.3725e-02,\n",
       "          6.8602e-02, -1.1294e-01,  4.4001e-02, -2.5884e-01,  1.6767e-01,\n",
       "          1.8316e-01,  5.6272e-02, -3.6874e-02, -2.7938e-02, -9.3204e-02,\n",
       "         -7.5239e-03,  4.1141e-02, -1.1542e-02, -9.9749e-02, -3.0910e-02,\n",
       "          4.1398e-02, -4.4389e-02, -2.6279e-02,  7.2100e-02,  7.5179e-03,\n",
       "         -7.4382e-03,  2.9311e-02, -1.3391e-02,  6.9966e-03, -9.3249e-03,\n",
       "          9.4272e-03, -1.1783e-02,  1.3849e-02,  1.8157e-03, -1.1522e-02,\n",
       "          1.3364e-02, -2.6307e-02,  2.3725e-03, -4.8451e-03,  6.2261e-03,\n",
       "          1.2653e-02,  1.7601e-02, -1.7971e-02, -2.9247e-03, -3.3447e-03,\n",
       "          1.4263e-02, -3.5629e-03, -9.2794e-03, -2.1326e-02,  1.9390e-02,\n",
       "          1.3287e-02, -8.7034e-03,  1.2936e-02, -2.0574e-02,  3.2204e-03,\n",
       "          5.9970e-03, -5.6524e-02,  3.0851e-02, -2.3233e-02,  4.6271e-02,\n",
       "         -1.4485e-03,  4.4248e-04, -3.1102e-02,  1.9762e-02,  2.0866e-02,\n",
       "          1.7914e-02, -2.0622e-02, -1.6030e-02,  6.2167e-03,  1.6809e-02,\n",
       "          4.6357e-03,  4.7169e-02, -2.1151e-02, -1.8898e-02,  3.5921e-02,\n",
       "          4.8621e-03, -5.9841e-02, -1.3029e-02,  5.6702e-03,  1.6820e-02,\n",
       "          2.1735e-02, -2.8285e-03, -1.5519e-02,  7.1974e-03,  3.5492e-02,\n",
       "         -2.3190e-02, -9.7930e-03,  2.3223e-02,  2.0529e-02,  2.7412e-02,\n",
       "          1.3887e-02,  1.7976e-03, -3.8905e-02,  1.8540e-02,  8.0013e-03,\n",
       "         -8.3682e-03, -8.6805e-03,  2.6464e-02,  1.8968e-03, -1.8028e-03,\n",
       "         -2.4427e-02, -3.5514e-02, -1.8748e-02, -3.0541e-02, -7.9520e-03,\n",
       "         -1.5989e-02,  9.3060e-03,  2.9318e-02,  1.6679e-02, -2.4060e-03,\n",
       "         -7.2656e-03, -2.7699e-03,  1.4280e-02, -6.7352e-02, -1.2329e-02,\n",
       "         -1.1516e-02, -8.0379e-03,  2.5604e-02, -2.9178e-02,  2.6076e-02,\n",
       "         -1.1561e-02, -4.0904e-03, -1.7735e-02, -2.8245e-03,  2.3919e-02,\n",
       "         -3.6326e-03, -1.6407e-03,  9.5295e-03,  2.4161e-02, -5.8965e-02,\n",
       "          4.7633e-02,  1.4403e-03, -4.4763e-02, -3.5462e-03,  3.0613e-02,\n",
       "          2.5047e-02,  1.3757e-02, -2.2238e-02,  8.0453e-03, -2.6188e-03,\n",
       "         -2.2013e-03, -6.0179e-03, -8.5149e-03, -2.8150e-02,  1.9282e-02,\n",
       "         -7.5657e-02,  6.1354e-03,  5.2562e-03, -2.2223e-03,  1.0437e-02,\n",
       "         -1.8630e-02, -7.7628e-02,  1.4377e-02,  1.4977e-02,  1.6090e-02,\n",
       "          2.9399e-02, -2.8604e-02, -3.2916e-02,  2.7902e-03,  1.4113e-02,\n",
       "          8.3836e-03, -6.5914e-03, -4.9576e-03, -1.5955e-02,  4.2381e-03,\n",
       "          3.0032e-02,  8.8986e-03, -1.5336e-02,  4.6771e-03, -1.2364e-02,\n",
       "         -3.7724e-02, -3.9060e-03,  1.4607e-02, -2.1286e-02,  9.7086e-03,\n",
       "         -1.5826e-02, -1.4847e-02,  1.0796e-03, -9.5035e-03, -1.8624e-02,\n",
       "         -3.1673e-02,  8.8388e-03, -1.4921e-02, -1.7855e-03,  3.8781e-02,\n",
       "          2.4269e-02, -1.6465e-03, -7.9774e-03, -1.3907e-02,  1.9653e-03,\n",
       "         -2.6717e-03,  3.0146e-02, -4.3986e-03,  6.0588e-03,  2.1959e-02,\n",
       "          2.0354e-02,  9.3631e-03, -8.4828e-03, -2.3994e-02,  1.8316e-02,\n",
       "         -2.2401e-02, -2.6273e-03,  3.2069e-03, -3.2386e-03,  1.1388e-02,\n",
       "          3.0835e-02,  2.6043e-02, -7.2103e-03, -5.0038e-04, -1.4860e-02,\n",
       "          2.3886e-02,  1.1530e-02, -1.0549e-03,  3.5677e-02,  6.0299e-03,\n",
       "          1.5875e-02,  5.3877e-02,  6.6331e-02,  1.5165e-02, -6.0870e-03,\n",
       "          1.6159e-03, -1.1137e-02,  1.3665e-02,  1.7698e-02,  4.5647e-03,\n",
       "         -4.5349e-02,  2.6634e-02,  4.7289e-03, -1.1664e-02,  8.7302e-03,\n",
       "          1.2051e-02,  2.3455e-02, -2.7151e-03, -1.3474e-02, -4.5949e-02,\n",
       "         -1.3496e-02,  8.1680e-02, -2.9737e-02, -2.8525e-02, -1.4888e-02,\n",
       "          5.4320e-03,  3.9142e-02,  1.4227e-02,  1.1140e-02, -1.0980e-02,\n",
       "          2.1982e-02, -1.1148e-02, -1.0226e-02, -5.8499e-03, -1.9739e-02,\n",
       "         -3.4634e-03, -1.0565e-02,  1.0449e-02,  8.2791e-03,  2.3053e-03,\n",
       "          9.7032e-03, -9.0916e-03,  5.4747e-04, -4.1901e-02,  9.6154e-03,\n",
       "          2.9424e-02,  1.1897e-03,  1.1825e-02,  2.7524e-02,  1.0225e-02,\n",
       "          2.1439e-02,  2.3448e-03, -3.7239e-02,  5.8888e-02, -3.1999e-02,\n",
       "         -7.9128e-03,  3.5337e-02,  2.7251e-02,  1.3948e-02,  1.0896e-02,\n",
       "          1.4326e-05, -2.6835e-03,  4.0720e-03,  1.6469e-02,  3.5876e-02,\n",
       "         -1.6803e-02,  2.8083e-02,  2.2789e-03,  3.1635e-02,  5.7104e-03,\n",
       "          3.0284e-03,  1.2528e-02, -1.7956e-02, -1.4686e-02,  4.4091e-03,\n",
       "         -1.4846e-02, -4.1044e-02, -3.4005e-02, -6.5876e-02,  3.0926e-02,\n",
       "          5.9820e-02, -1.0069e-04, -6.6089e-03,  2.1271e-03,  3.6137e-03,\n",
       "          9.0073e-03,  9.6992e-03,  2.1992e-02,  6.2104e-02,  1.4786e-02,\n",
       "         -2.6120e-02, -1.4990e-02,  1.5148e-02,  3.0313e-02,  2.0834e-02,\n",
       "          1.7836e-02, -5.4321e-03, -5.9164e-03,  1.7840e-02, -4.3020e-03,\n",
       "          8.7374e-03, -2.4993e-02,  3.4310e-02,  2.2652e-02, -5.3760e-03,\n",
       "          1.7668e-02, -8.9518e-04,  1.3691e-03, -2.1373e-02, -6.1878e-03,\n",
       "         -1.2396e-02, -1.7816e-02, -1.8014e-02,  9.5274e-03,  1.1643e-02,\n",
       "         -2.0683e-02, -2.8707e-03,  1.1669e-02,  1.5618e-02,  3.5348e-02,\n",
       "         -1.1234e-02, -4.5453e-03, -3.4890e-02, -3.0010e-02,  1.6433e-02,\n",
       "         -1.2068e-02,  8.2583e-03,  1.4090e-02,  1.8771e-02, -4.9337e-02,\n",
       "         -1.7775e-03,  5.6333e-02,  6.8979e-02,  2.3123e-02, -1.0754e-02,\n",
       "         -4.9530e-02,  4.2980e-02,  2.8846e-02, -3.9176e-02,  8.1903e-02,\n",
       "         -2.9344e-02,  3.0343e-02,  8.4269e-02, -2.4376e-02, -8.4680e-02,\n",
       "          6.7452e-03,  1.2407e-01,  1.5680e-02, -1.6643e-02,  9.0987e-03,\n",
       "         -2.7984e-03,  7.5874e-02, -1.4630e-02,  2.9823e-02, -1.0423e-02,\n",
       "         -6.0341e-02, -3.6580e-02, -5.4615e-02, -1.3628e-01, -5.8373e-02,\n",
       "          4.3453e-02,  3.0439e-02,  1.7298e-02, -1.1724e-01,  1.0805e-01,\n",
       "         -4.6345e-02, -1.1533e-01,  7.4684e-02, -5.9752e-03,  4.3189e-02,\n",
       "          4.4795e-02, -3.7566e-03, -7.5097e-02,  3.5959e-02,  1.3906e-01,\n",
       "          4.6041e-02,  1.1786e-02,  1.1243e-01,  8.4072e-02, -7.7309e-02,\n",
       "          1.3586e-02,  9.5244e-02, -1.2002e-01,  7.0882e-02,  1.0043e-01,\n",
       "          2.5874e-02,  2.3354e-02, -3.5469e-02,  3.0738e-02,  1.0479e-01,\n",
       "         -9.2843e-02,  5.9718e-02, -1.9409e-02, -3.4414e-02, -8.4060e-03,\n",
       "         -9.3654e-03, -2.8030e-02,  7.2026e-03, -5.9461e-03, -1.2284e-02,\n",
       "         -1.7473e-02, -4.9678e-02,  1.0224e-02, -1.4688e-02, -1.7345e-02,\n",
       "          2.6771e-02, -2.6582e-02, -2.9768e-02,  6.2005e-03, -3.3405e-04,\n",
       "          9.1245e-03, -3.7149e-02, -6.7714e-03, -1.8193e-02,  3.4191e-02,\n",
       "         -5.5732e-03, -2.6161e-02, -1.4078e-02,  1.0288e-02, -2.2850e-02,\n",
       "         -2.2642e-02,  1.0270e-02,  6.9930e-03,  1.3614e-03, -2.9319e-04,\n",
       "          9.9593e-03, -6.0532e-03,  1.8669e-03, -5.3395e-03, -2.2013e-02,\n",
       "          8.4485e-03, -1.9142e-02,  1.0449e-02, -1.6700e-02,  1.3038e-02,\n",
       "          7.7479e-03, -1.3329e-02,  1.3052e-02, -2.5305e-03,  1.6191e-02,\n",
       "          1.3152e-02,  2.9897e-02,  8.5553e-03, -6.4898e-04,  1.2359e-02,\n",
       "         -4.2144e-03,  2.1785e-02,  2.1401e-02, -1.3295e-02,  7.4764e-03,\n",
       "          6.3580e-03, -6.2467e-03,  1.8235e-02,  3.0643e-02, -4.9091e-03,\n",
       "         -1.3889e-02,  2.6181e-03,  4.9702e-03, -6.1664e-03, -2.8528e-03,\n",
       "         -4.0556e-04,  5.4844e-03,  9.7783e-03,  1.2326e-02, -1.6844e-02,\n",
       "         -1.6294e-02,  4.9879e-03,  3.7789e-03,  8.0305e-04,  2.0482e-02,\n",
       "         -1.6369e-02,  1.6436e-03, -9.0401e-03, -3.2635e-02, -2.3990e-03,\n",
       "          5.7569e-03, -2.0392e-02,  6.6946e-03, -1.8541e-02,  9.3559e-03,\n",
       "          2.7165e-02,  1.2492e-02,  1.2748e-03, -1.3846e-03,  4.0312e-03,\n",
       "         -8.5552e-03,  3.1621e-03, -3.9514e-02, -3.7938e-03, -1.3551e-02,\n",
       "          2.2692e-02, -1.0217e-02, -1.2839e-02, -4.8771e-03, -4.2620e-03,\n",
       "         -3.0481e-02,  4.6085e-02, -2.8627e-03,  6.6756e-03, -2.6765e-03,\n",
       "         -4.1443e-02,  1.3336e-02, -1.0526e-02, -3.8494e-02,  1.2780e-02,\n",
       "         -3.5214e-02, -2.4758e-02,  7.5220e-03,  1.7225e-02, -1.6440e-02,\n",
       "         -3.6639e-03, -4.7462e-02,  5.3796e-04, -2.8419e-03,  4.5923e-03,\n",
       "         -3.0517e-02, -3.6832e-03,  1.8710e-02, -3.0486e-02, -2.4076e-02,\n",
       "         -2.7601e-02,  1.1921e-01,  1.2020e-01,  5.9805e-02, -6.9238e-03,\n",
       "         -1.3529e-01,  1.1234e-01,  8.3534e-02,  1.9974e-01,  5.3834e-02,\n",
       "         -6.6691e-02,  1.2676e-01,  2.4947e-01,  4.9879e-01, -1.6342e-01,\n",
       "          6.1663e-02, -4.8022e-02, -5.4069e-02,  4.7277e-02, -1.4724e-01,\n",
       "          8.4666e-02,  9.8618e-02,  7.9988e-02, -5.7652e-02,  6.3551e-03,\n",
       "          2.6916e-03,  9.2017e-02,  1.2511e-01,  2.5168e-01, -8.6152e-02,\n",
       "         -2.7570e-02, -6.1548e-02,  9.1371e-02,  8.0129e-02, -1.1662e-01,\n",
       "          1.5206e-01, -1.0687e-01, -1.0758e-01,  9.4138e-02,  1.0322e-01,\n",
       "         -1.5152e-01,  2.5472e-01,  7.0699e-02, -4.1571e-02,  2.7933e-02,\n",
       "         -1.9523e-01, -2.8319e-01,  5.9689e-02, -1.4707e-01, -3.5683e-02,\n",
       "         -5.4465e-02,  1.2570e-01, -1.2280e-01,  2.0263e-01, -1.0653e-02,\n",
       "          1.1058e-01, -9.1731e-04,  8.6605e-02, -1.7707e-02,  1.2616e-02,\n",
       "          1.8871e-01, -1.0594e-01, -3.7989e-03, -6.6359e-02, -5.9799e-02,\n",
       "          4.3201e-03, -2.3140e-02,  4.8008e-03,  1.4294e-02, -9.5453e-03,\n",
       "          5.8454e-03,  8.6512e-03,  2.1151e-02,  1.7098e-02, -1.4637e-03,\n",
       "          1.3778e-02, -1.2843e-02,  2.3742e-02, -1.3895e-02,  1.1327e-03,\n",
       "         -7.0846e-03, -7.6255e-03, -8.2264e-03, -1.5513e-02,  4.2724e-03,\n",
       "         -1.7624e-02, -3.0984e-03, -1.4400e-02,  2.3883e-02,  1.1556e-01,\n",
       "          4.4036e-02,  3.2821e-02,  8.6612e-04,  1.2383e-02, -6.6263e-03,\n",
       "         -2.7201e-03,  4.8125e-03, -2.8362e-03,  3.9830e-02,  5.2414e-02,\n",
       "         -4.6269e-03, -1.5858e-02,  2.1845e-02, -1.3767e-02, -1.0629e-02,\n",
       "          1.0347e-02, -3.4209e-02,  1.6939e-02,  1.8120e-02,  3.0650e-03,\n",
       "         -2.5109e-03,  1.3500e-02, -3.6440e-02, -9.2135e-03,  9.2194e-03,\n",
       "         -3.6276e-02, -1.1555e-02, -1.9569e-02, -1.5417e-02, -2.0485e-02,\n",
       "          2.9770e-03, -6.8246e-03, -6.5039e-03, -1.2597e-02, -1.1409e-02,\n",
       "          1.7139e-02,  4.6424e-03, -5.1774e-02, -1.1679e-02,  5.2761e-03,\n",
       "         -1.3664e-02, -1.4001e-02,  2.0379e-03,  1.2753e-02, -8.1607e-03,\n",
       "         -1.0849e-02, -1.0683e-03, -2.4489e-03,  2.0192e-02,  1.5756e-02,\n",
       "         -6.4964e-03, -4.5603e-02, -2.5999e-02, -1.4307e-02, -7.4639e-03,\n",
       "          9.9480e-03,  1.6763e-02,  2.1737e-02,  4.8181e-02,  1.7739e-02,\n",
       "          1.1469e-02, -4.2359e-03, -1.6419e-02, -1.7318e-02,  1.1498e-03,\n",
       "          2.4485e-02, -3.0614e-03,  1.9017e-02, -1.6453e-02, -1.3444e-02,\n",
       "          2.6748e-02, -6.4994e-03,  5.1485e-03,  1.4132e-02, -1.1573e-02,\n",
       "          1.2583e-02, -1.1401e-02, -2.0003e-02, -3.8115e-03,  7.3728e-03,\n",
       "          1.5500e-02,  2.0623e-02,  3.1582e-03, -1.2794e-02,  4.5499e-03,\n",
       "         -3.3994e-04, -2.3003e-02,  1.2225e-02, -2.7949e-02, -9.6121e-03,\n",
       "         -3.5844e-02, -4.2373e-03,  5.3473e-03,  1.4432e-02, -1.2745e-02,\n",
       "          7.1483e-03,  2.9170e-03,  6.2454e-03,  6.8991e-03,  1.5852e-02,\n",
       "          2.1877e-02, -1.7211e-02, -2.6093e-02]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model's saving\n",
    "list(pipe.model.state_dict().items())[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6bd2f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To re-use later with Path.stat()\n",
    "torch.save(pipe.model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca26a44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_size(self):\n",
    "    \"\"\"This overrides the PerformanceBenchmark.compute_size() method\"\"\"\n",
    "    state_dict = self.pipeline.model.state_dict()\n",
    "    tmp_path = Path(\"model.pt\")\n",
    "    torch.save(state_dict, tmp_path)\n",
    "    # Calculate size in megabytes\n",
    "    size_mb = Path(tmp_path).stat().st_size / (1024 * 1024)\n",
    "    # Delete temporary file\n",
    "    tmp_path.unlink()\n",
    "    print(f\"Model size (MB) - {size_mb:.2f}\")\n",
    "    return {\"size_mb\": size_mb}\n",
    "\n",
    "PerformanceBenchmark.compute_size = compute_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31da218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency (ms) - 268.238\n",
      "Latency (ms) - 88.979\n",
      "Latency (ms) - 101.287\n"
     ]
    }
   ],
   "source": [
    "# Model Performance Counter() - Average Latency per Query as follow:\n",
    "for _ in range(3):\n",
    "    start_time = perf_counter()\n",
    "    _ = pipe(query)\n",
    "    latency = perf_counter() - start_time\n",
    "    print(f\"Latency (ms) - {1000 * latency:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266c9d09",
   "metadata": {},
   "source": [
    "##### CPU warm-up for time run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdd71116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_pipeline(self, query=\"What is the pin number for my account?\"):\n",
    "    \"\"\"This overrides the PerformanceBenchmark.time_pipeline() method\"\"\"\n",
    "    latencies = []\n",
    "    # Warmup\n",
    "    for _ in range(10):\n",
    "        _ = self.pipeline(query)\n",
    "    # Timed run\n",
    "    for _ in range(100):\n",
    "        start_time = perf_counter()\n",
    "        _ = self.pipeline(query)\n",
    "        latency = perf_counter() - start_time\n",
    "        latencies.append(latency)\n",
    "    # Compute run statistics\n",
    "    time_avg_ms = 1000 * np.mean(latencies)\n",
    "    time_std_ms = 1000 * np.std(latencies)\n",
    "    print(f\"Average latency (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f}\")\n",
    "    return {\"time_avg_ms\": time_avg_ms, \"time_std_ms\": time_std_ms}\n",
    "\n",
    "PerformanceBenchmark.time_pipeline = time_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7fbf472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 418.15\n",
      "Average latency (ms) - 71.05 +\\- 51.84\n",
      "Accuracy on test set - 0.867\n"
     ]
    }
   ],
   "source": [
    "pb = PerformanceBenchmark(pipe, clinc[\"test\"])\n",
    "perf_metrics = pb.run_benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b24b82",
   "metadata": {},
   "source": [
    "## Making Models Smaller via Knowledge Distillation\n",
    "\n",
    "### Knowledge Distillation for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1be299c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
