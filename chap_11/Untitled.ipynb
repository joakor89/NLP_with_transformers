{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354f8cc5",
   "metadata": {},
   "source": [
    "# Future Directions\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b074f0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing \n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "from transformers.models.gpt2.tokenization_gpt2 import bytes_to_unicode\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "# Datasets\n",
    "from datasets import load_dataset, DownloadConfig\n",
    "\n",
    "# Images\n",
    "from PIL import Image\n",
    "\n",
    "# \n",
    "import soundfile as sf\n",
    "\n",
    "# \n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34db140",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da17aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you're on Colab or Kaggle\n",
    "!git clone https://github.com/nlp-with-transformers/notebooks.git\n",
    "%cd notebooks\n",
    "\n",
    "from install import *\n",
    "install_requirements(is_chapter11=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c410f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "setup_chapter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f86e8e",
   "metadata": {},
   "source": [
    "### Scaling Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a433ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = [\n",
    "    {'date': '12-06-2017', 'name': 'Transformer', 'size': 213*1e6},\n",
    "    {'date': '11-06-2018', 'name': 'GPT', 'size': 110*1e6},\n",
    "    {'date': '11-10-2018', 'name': 'BERT', 'size': 340*1e6},\n",
    "    {'date': '14-02-2019', 'name': 'GPT-2', 'size': 1.5*1e9},\n",
    "    {'date': '23-10-2019', 'name': 'T5', 'size': 11*1e9},\n",
    "    {'date': '17-09-2019', 'name': 'Megatron', 'size': 8.3*1e9},\n",
    "    {'date': '13-02-2020', 'name': 'Turing-NLG', 'size': 17*1e9},\n",
    "    {'date': '30-06-2020', 'name': 'GShard', 'size': 600*1e9},\n",
    "    {'date': '28-05-2020', 'name': 'GPT-3', 'size': 175*1e9},\n",
    "    {'date': '11-01-2021', 'name': 'Switch-C', 'size': 1.571*10e12},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f41ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_point(x, y, val, ax):\n",
    "    a = pd.concat({\"x\": x, \"y\": y, \"val\": val}, axis=1)\n",
    "    for i, point in a.iterrows():\n",
    "        ax.text(\n",
    "            point[\"x\"],\n",
    "            point[\"y\"],\n",
    "            str(point[\"val\"]),\n",
    "            horizontalalignment=\"center\",\n",
    "            verticalalignment=\"bottom\",\n",
    "        )\n",
    "\n",
    "\n",
    "df_lm = pd.DataFrame.from_records(model_data)\n",
    "df_lm[\"date\"] = pd.to_datetime(df_lm[\"date\"], dayfirst=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "df_lm.plot(x=\"date\", y=\"size\", kind=\"scatter\", s=15, ax=ax)\n",
    "ax.set_yscale(\"log\")\n",
    "label_point(df_lm[\"date\"], df_lm[\"size\"], df_lm[\"name\"], ax)\n",
    "ax.set_xlabel(\"Release date\")\n",
    "ax.set_ylabel(\"Number of parameters\")\n",
    "ax.grid(True)\n",
    "plt.subplots_adjust(top=1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e17481",
   "metadata": {},
   "source": [
    "### ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99f6669",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"images/doge.jpg\")\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22072cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifier = pipeline(\"image-classification\")\n",
    "preds = image_classifier(image)\n",
    "preds_df = pd.DataFrame(preds)\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a185a59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data = [\n",
    "    {\"chapter\": 0, \"name\": \"Introduction\", \"start_page\": 1, \"end_page\": 11},\n",
    "    {\"chapter\": 1, \"name\": \"Text classification\", \"start_page\": 12, \n",
    "     \"end_page\": 48},\n",
    "    {\"chapter\": 2, \"name\": \"Named Entity Recognition\", \"start_page\": 49,\n",
    "     \"end_page\": 73},\n",
    "    {\"chapter\": 3, \"name\": \"Question Answering\", \"start_page\": 74, \n",
    "     \"end_page\": 120},\n",
    "    {\"chapter\": 4, \"name\": \"Summarization\", \"start_page\": 121, \n",
    "     \"end_page\": 140},\n",
    "    {\"chapter\": 5, \"name\": \"Conclusion\", \"start_page\": 141, \n",
    "     \"end_page\": 144}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc2dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(book_data)\n",
    "table['number_of_pages'] = table['end_page']-table['start_page']\n",
    "table = table.astype(str)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380186c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_qa = pipeline(\"table-question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ca5dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_qa = pipeline(\"table-question-answering\")\n",
    "queries = [\"What's the topic in chapter 4?\",\n",
    "           \"What is the total number of pages?\",\n",
    "           \"On which page does the chapter about question-answering start?\",\n",
    "           \"How many chapters have more than 20 pages?\"]\n",
    "preds = table_qa(table, queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d7c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query, pred in zip(queries, preds):\n",
    "    print(query)\n",
    "    if pred[\"aggregator\"] == \"NONE\": \n",
    "        print(\"Predicted answer: \" + pred[\"answer\"])\n",
    "    else: \n",
    "        print(\"Predicted answer: \" + pred[\"answer\"])\n",
    "    print('='*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5044c1",
   "metadata": {},
   "source": [
    "### Multimodal Transformers\n",
    "\n",
    "#### Speech-to-Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86683136",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr = pipeline(\"automatic-speech-recognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5d7378",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"superb\", \"asr\", split=\"validation[:1]\")\n",
    "print(ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5298f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "ds = ds.map(map_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e5d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(ds[0]['speech'], rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba920903",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_format(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1dad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = asr(ds[0][\"speech\"])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c45028c",
   "metadata": {},
   "source": [
    "### CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67719f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_ckpt = \"openai/clip-vit-base-patch32\"\n",
    "model = CLIPModel.from_pretrained(clip_ckpt)\n",
    "processor = CLIPProcessor.from_pretrained(clip_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd6ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"images/optimusprime.jpg\")\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35beb0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"a photo of a transformer\", \"a photo of a robot\", \"a photo of agi\"]\n",
    "inputs = processor(text=texts, images=image, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image\n",
    "probs = logits_per_image.softmax(dim=1)\n",
    "probs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
